<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, user-scalable=0, initial-scale=1.0"
    />
    <title>Hello WebXR!</title>

    <style>
      body {
        margin: 0;
        overflow: hidden;
        background-color: #1f1f1f;
      }
      #container {
        position: fixed;
        width: 100%;
        height: 100%;
      }
      .video-feed {
        position: fixed;
        right: 10px;
        bottom: 10px;
        border: 2px solid white;
        z-index: 100;
        width: auto;
        height: auto;
        width: 100px;
        height: 100px;
      }

      #debug-text {
        position: fixed;
        top: 10px;
        left: 10px;
        color: white;
        font-family: monospace;
        z-index: 100;
        white-space: pre;
        font-size: 12px;
        background-color: rgba(0, 0, 0, 0.5);
        padding: 10px;
        border-radius: 5px;
      }
    </style>

    <!-- three.js -->
    <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>

    <script src="./modules/camera_utils.js"></script>
    <script src="./modules/drawing_utils.js"></script>
    <script src="./modules/hands.js"></script>
    <script src="./modules/draw_hand_style.js"></script>
    <script src="./modules/hand_faust_params.js"></script>
    <script src="./modules/misc_utils.js"></script>
    <script src="./faust_index.js"></script>

    <!-- Add these imports after the three.js script -->
    <script src="https://unpkg.com/three@0.126.0/examples/js/postprocessing/EffectComposer.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/postprocessing/RenderPass.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/postprocessing/ShaderPass.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/shaders/CopyShader.js"></script>

    <!-- Add before the type="module" script -->
    <script id="vertexShader" type="x-shader/x-vertex">
      varying vec2 vUv;
      void main() {
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
      uniform sampler2D tDiffuse;
      uniform float distortion;
      uniform float distortion2;
      uniform float scale;
      varying vec2 vUv;

      void main() {
        vec2 uv = vUv;
        vec2 d = uv - 0.5;
        float r2 = dot(d, d);
        float barrel = 1.0 + r2 * (distortion + distortion2 * r2);

        uv = 0.5 + (d * barrel * scale);

        vec4 tex = vec4(0.0);
        if (uv.x >= 0.0 && uv.x <= 1.0 && uv.y >= 0.0 && uv.y <= 1.0) {
          tex = texture2D(tDiffuse, uv);
        }

        gl_FragColor = tex;
      }
    </script>

    <script
      type="module"
      src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619/face_mesh.js"
    ></script>

    <!-- Add before your module script -->
    <script
      type="module"
      src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs"
    ></script>

    <script type="module">
      // all taken from https://cdn.jsdelivr.net/npm/@mediapipe/hands

      // needs to find:
      // http://localhost:8080/modules/hand_landmark_full.tflite
      // http://localhost:8080/modules/hands_solution_packed_assets_loader.js
      // http://localhost:8080/modules/hands_solution_simd_wasm_bin.js
      // http://localhost:8080/modules/hands.binarypb

      // https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/hands_solution_packed_assets.data

      import {
        FilesetResolver,
        FaceDetector,
      } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs";

      let scene, camera, renderer, lastLandmarks;
      const videoElement = document.createElement("video");
      videoElement.classList.add("video-feed");
      document.body.appendChild(videoElement);

      const SHADERS_ENABLED = false;

      // Add these lines to create video texture and plane
      const videoTexture = new THREE.VideoTexture(videoElement);
      let aspectRatio = 16 / 9;
      let composer;

      const scaler = {
        x: 1 * aspectRatio * 1.5,
        y: 1 * 3,
        z: 1,
      };

      let LensDistortionShader = {
        uniforms: {
          tDiffuse: { value: null },
          distortion: { value: 0.3 },
          distortion2: { value: 0.8 },
          scale: { value: 0.8 },
        },
        vertexShader: document.getElementById("vertexShader").textContent,
        fragmentShader: document.getElementById("fragmentShader").textContent,
      };

      const planeGeometry = new THREE.PlaneGeometry(10, 10, 10, 10);
      const planeMaterial = new THREE.MeshBasicMaterial({
        map: videoTexture,
        side: THREE.DoubleSide,
      });
      const plane = new THREE.Mesh(planeGeometry, planeMaterial);
      // Position the plane behind other elements
      plane.position.z = -4;

      // plane.scale.set(scaler.x, scaler.y, scaler.z);
      // Scale the plane to fill the view
      // plane.scale.set(1.5, 1.5, 1.5);
      plane.renderOrder = -1;

      // Initialize Three.js scene
      const container = document.getElementById("container");
      const threeScene = createScene(container);
      scene = threeScene.scene;
      camera = threeScene.camera;
      renderer = threeScene.renderer;

      renderer.getContext().enableVertexAttribArray(1);

      // Add the plane to the scene
      scene.add(plane);

      const attachFaustNode = async () => {
        await faustNode.then((faustNode) => {
          console.log("faustNode", faustNode.setParamValue);
          window.faustNode = faustNode;
          faustNode.setParamValue("/hand_synth/gate", 1.0);
          console.log("faustNode attached");
        });
      };

      // Add after renderer initialization

      // Replace or modify the createScene function
      function createScene(container) {
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(
          75,
          window.innerWidth / window.innerHeight,
          0.1,
          10000
        );
        camera.position.z = 5;

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        container.appendChild(renderer.domElement);

        // Add post-processing setup
        composer = new THREE.EffectComposer(renderer);
        const renderPass = new THREE.RenderPass(scene, camera);
        composer.addPass(renderPass);

        if (SHADERS_ENABLED) {
          const distortionPass = new THREE.ShaderPass(LensDistortionShader);
          distortionPass.renderToScreen = true;
          composer.addPass(distortionPass);
        }

        return { scene, camera, renderer };
      }

      // Modify the animate function
      function animate() {
        requestAnimationFrame(animate);

        const positions = plane.geometry.attributes.position;
        let lastLandmarks = window.lastLandmarks;

        if (SHADERS_ENABLED) {
          // Add animation for distortion
          const time = Date.now() * 0.001; // Convert to seconds
          const distortionValue = 0.3 + Math.sin(time) * 0.2; // Oscillate between 0.1 and 0.5
          composer.passes[1].uniforms.distortion.value = distortionValue;
          composer.render();
        } else {
          renderer.render(scene, camera);
        }
      }

      animate();

      const debugDiv = document.createElement("div");
      debugDiv.id = "debug-text";
      document.body.appendChild(debugDiv);

      const showDebugText = (results) => {
        let debugText = "";
        if (results.multiHandLandmarks.length === 0) {
          debugText = "No hands detected";
          updateFaustParamsNoLandmarks(window.faustNode);
        } else {
          debugText = results.multiHandLandmarks
            .map((landmarks, index) => formatLandmarks(landmarks, index))
            .join("\n\n");
        }
        debugDiv.textContent = debugText;
      };

      function formatLandmarks(landmarks, handIndex) {
        const landmarkNames = [
          "wrist",
          "thumb_cmc",
          "thumb_mcp",
          "thumb_ip",
          "thumb_tip",
          "index_mcp",
          "index_pip",
          "index_dip",
          "index_tip",
          "middle_mcp",
          "middle_pip",
          "middle_dip",
          "middle_tip",
          "ring_mcp",
          "ring_pip",
          "ring_dip",
          "ring_tip",
          "pinky_mcp",
          "pinky_pip",
          "pinky_dip",
          "pinky_tip",
        ];

        return landmarks
          .map((landmark, i) => {
            return (
              `Hand ${handIndex + 1} - ${landmarkNames[i]}:` +
              `  x: ${landmark.x.toFixed(3)}` +
              `  y: ${landmark.y.toFixed(3)}` +
              `  z: ${landmark.z.toFixed(8)}`
            );
          })
          .join("\n");
      }

      function onResults(results) {
        // Modify the scene clearing to preserve the video plane
        const objectsToRemove = scene.children.filter(
          (child) => child !== plane
        );

        objectsToRemove.forEach((object) => scene.remove(object));

        window.lastLandmarks = results.multiHandLandmarks;

        if (results.multiHandLandmarks) {
          updateFaustParamsForLandmarks(window.faustNode);
          showDebugText(results);
          let i = 0;
          for (const landmarks of results.multiHandLandmarks) {
            // Transform landmarks to match plane coordinates
            const transformedLandmarks = landmarks.map((landmark) => ({
              x: (landmark.x - 0.5) * scaler.x + 0.5,
              y: (landmark.y - 0.5) * scaler.y + 0.5,
              z: landmark.z * scaler.z || 0,
            }));

            // if (i === LANDMARKS.INDEX_FINGER_TIP) {
            // console.log(landmarks[i].x, transformedLandmarks[i].x);
            // }

            drawConnectors(scene, transformedLandmarks, HAND_CONNECTIONS, {
              color: 0x00ff00,
              lineWidth: 2,
            });

            drawLandmarks(scene, transformedLandmarks, {
              color: 0xffffff,
              radius: 4,
              scaler: scaler,
            });

            updateFaustParams(window.faustNode, landmarks); // Keep original landmarks for Faust params
            ++i;
          }
        }
      }

      const hands = new Hands({
        locateFile: (file) => `./modules/hands_files/${file}`,
      });

      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });

      hands.onResults(onResults);

      // Add this import after the existing mediapipe import

      // console.log("AHHHHHHHHHHHHHHHHH", FilesetResolver);

      // Add these declarations near the top of your module script
      // import { FaceMesh } from "@mediapipe/face_mesh";
      // import { FilesetResolver, FaceDetector } from "@mediapipe/tasks-vision";

      // Remove the incorrect face detector initialization and replace with:
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );

      const faceDetector = await FaceDetector.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`,
          delegate: "GPU",
        },
        runningMode: "VIDEO",
      });

      const faceMesh = new FaceMesh({
        locateFile: (file) => {
          return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
        },
      });

      // Add face mesh results handler
      faceMesh.onResults((results) => {
        if (results.multiFaceLandmarks) {
          for (const landmarks of results.multiFaceLandmarks) {
            // You can add face mesh visualization here similar to hand landmarks

            const transformedLandmarks = landmarks.map((landmark) => ({
              x: (landmark.x - 0.5) * scaler.x + 0.5,
              y: (landmark.y - 0.5) * scaler.y + 0.5,
              z: landmark.z * scaler.z || 0,
            }));

            drawLandmarks(scene, transformedLandmarks, {
              color: 0x0000ff,
              lineWidth: 1,
            });
          }
        }
      });

      // Modify your camera setup to process both hands and face
      const canvasCamera = new Camera(videoElement, {
        onFrame: async () => {
          await hands.send({ image: videoElement });
          await faceMesh.send({ image: videoElement });
        },
        width: window.innerWidth,
        height: window.innerHeight,
        facingMode: "environment",
      });
      // videoElement.style.visibility = "hidden";
      canvasCamera.start();
      console.log(canvasCamera);

      // aspectRatio = canvasCamera.h.width / canvasCamera.h.height;

      await attachFaustNode();
    </script>
  </head>

  <body>
    <div id="container"></div>
  </body>
</html>

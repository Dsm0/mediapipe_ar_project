<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, user-scalable=0, initial-scale=1.0"
    />
    <title>Hello WebXR!</title>

    <link rel="stylesheet" href="style.css" />

    <!-- three.js -->

    <script src="./modules/landmarks.js"></script>
    <script src="./modules/camera_utils.js"></script>
    <script src="./modules/hands.js"></script>
    <script src="./modules/draw_style.js"></script>
    <script src="./modules/drawing_utils.js"></script>
    <script src="./modules/faust_params.js"></script>
    <script src="./modules/misc_utils.js"></script>
    <script src="./faust_index.js"></script>

    <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
    <!-- Add these imports after the three.js script -->
    <script src="https://unpkg.com/three@0.126.0/examples/js/postprocessing/EffectComposer.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/postprocessing/RenderPass.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/postprocessing/ShaderPass.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/shaders/CopyShader.js"></script>

    <script src="./modules/threejs/three.js"></script>
    <!-- Add these imports after the three.js script -->
    <script src="./modules/threejs/EffectComposer.js"></script>
    <script src="./modules/threejs/RenderPass.js"></script>
    <script src="./modules/threejs/ShaderPass.js"></script>
    <script src="./modules/threejs/CopyShader.js"></script>

    <!-- Add before the type="module" script -->
    <script id="vertexShader" type="x-shader/x-vertex">
      varying vec2 vUv;
      void main() {
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
      uniform sampler2D tDiffuse;
      uniform sampler2D tPrevious;
      uniform float distortion;
      uniform float distortion2;
      uniform float scale;
      uniform vec3 leftEyePoints[15];
      uniform vec3 rightEyePoints[15];
      varying vec2 vUv;

      // This function checks if a given 2D point is inside a polygon defined by a set of 3D points.
      // The polygon is assumed to be a simple polygon (not self-intersecting).
      bool isInsideEye(vec2 point, vec3 polygon[15]) {
          bool inside = false; // Initialize a flag to track if the point is inside the polygon
          int j = 14; // Initialize the index of the previous point in the polygon

          // Iterate over each point in the polygon
          for (int i = 0; i < 15; i++) {
              // Convert the current and previous 3D points to 2D points
              vec2 pi = vec2((polygon[i].x), (polygon[i].y));
              vec2 pj = vec2((polygon[j].x), (polygon[j].y));

              // Check if the point is on the edge formed by pi and pj
              if (((pi.y > point.y) != (pj.y > point.y)) &&
                  (point.x < (pj.x - pi.x) * (point.y - pi.y) / (pj.y - pi.y) + pi.x)) {
                  // If the point is on the edge, toggle the inside flag
                  inside = !inside;
              }
              // Move to the next point in the polygon
              j = i;
          }
          // Return the final state of the inside flag
          return inside;
      }

      void main() {
          vec2 uv = vUv;
          vec2 d = uv - 0.5;
          float r2 = dot(d, d);

          float barrel;

          barrel = 1.0 + r2 * (distortion + distortion2 * r2);

          // if (inEyeRegion) {
          //     barrel = 1.0 + r2 * (distortion * 2.0 + distortion2 * r2);
          // }

          uv = 0.5 + (d * barrel * scale);

          bool inRightEyeRegion = isInsideEye(uv, rightEyePoints);
          bool inLeftEyeRegion = isInsideEye(uv, leftEyePoints);

          vec4 tex = texture2D(tDiffuse, uv);
          vec4 prevTex = texture2D(tPrevious, uv);

          // tex = mix(tex, prevTex, 0.5);

          if (uv.x >= 0.0 && uv.x <= 1.0 && uv.y >= 0.0 && uv.y <= 1.0) {
              if (inLeftEyeRegion || inRightEyeRegion) {
                  // Blend current frame with previous frame in eye regions
                  tex = vec4(0.0, 0.0, 0.0, 1.0);
              }
          }

          // for (int i = 0; i < 15; i++) {
          //     vec2 pi = vec2(rightEyePoints[i].x, rightEyePoints[i].y);
          //     if (distance(uv, pi) < 0.01) {
          //         tex = vec4(0.0, 0.0, 0.0, 1.0); // Black dot
          //     }
          // }

          // Draw an unfilled square border
          float border = 0.01; // Border thickness
          if ((abs(uv.x - 0.5) > 0.5 - border && abs(uv.x - 0.5) < 0.5) ||
              (abs(uv.y - 0.5) > 0.5 - border && abs(uv.y - 0.5) < 0.5)) {
              tex = vec4(1.0, 0.0, 0.0, 1.0); // Red border
          }


          for (float y = 0.25; y <= 0.75; y += 0.25) {
              for (float x = 0.25; x <= 0.75; x += 0.25) {
                  if (abs(uv.x - x) < 0.005 && abs(uv.y - y) < 0.005) {
                      tex = vec4(1.0, 1.0, 1.0, 1.0); // White dot
                  }
              }
          }

          // tex = prevTex;


           gl_FragColor = tex;
      }
    </script>

    <script
      type="module"
      src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619/face_mesh.js"
    ></script>

    <!-- Add before your module script -->
    <script
      type="module"
      src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs"
    ></script>

    <script type="module">
      // all taken from https://cdn.jsdelivr.net/npm/@mediapipe/hands

      // needs to find:
      // http://localhost:8080/modules/hand_landmark_full.tflite
      // http://localhost:8080/modules/hands_solution_packed_assets_loader.js
      // http://localhost:8080/modules/hands_solution_simd_wasm_bin.js
      // http://localhost:8080/modules/hands.binarypb

      // https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/hands_solution_packed_assets.data

      import {
        FilesetResolver,
        FaceDetector,
      } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs";

      let scene, camera, renderer;
      const videoElement = document.createElement("video");
      videoElement.classList.add("video-feed");
      document.body.appendChild(videoElement);

      const SHADERS_ENABLED = true;

      // Add these lines to create video texture and plane
      const videoTexture = new THREE.VideoTexture(videoElement);
      let aspectRatio = window.innerWidth / window.innerHeight;
      let composer;

      const scaler = {
        x: 1 * aspectRatio * 1.1,
        y: 1,
        z: 1,
      };

      const pointScaler = {
        x: scaler.x * 2.75,
        y: scaler.y * 2.75,
        z: scaler.z * 2.75,
      };

      let minZValue = Infinity;
      let maxZValue = -Infinity;

      const findZRange = (zValue) => {
        minZValue = Math.min(minZValue, zValue);
        maxZValue = Math.max(maxZValue, zValue);
        console.log(minZValue, maxZValue);
      };

      let leftEyePoints = [
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
      ];

      let rightEyePoints = [
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
        new THREE.Vector3(0, 0, 0),
      ];

      let LensDistortionShader = {
        uniforms: {
          tDiffuse: { value: null },
          tPrevious: { value: null },
          distortion: { value: 0.3 },
          distortion2: { value: 0.8 },
          scale: { value: 0.8 },
          leftEyePoints: { value: leftEyePoints },
          rightEyePoints: { value: rightEyePoints },
        },
        vertexShader: document.getElementById("vertexShader").textContent,
        fragmentShader: document.getElementById("fragmentShader").textContent,
      };

      const planeGeometry = new THREE.PlaneGeometry(10, 10, 10, 10);
      const planeMaterial = new THREE.MeshBasicMaterial({
        map: videoTexture,
        side: THREE.DoubleSide,
      });
      const plane = new THREE.Mesh(planeGeometry, planeMaterial);
      // Position the plane behind other elements
      plane.position.z = -4;

      plane.scale.set(scaler.x, scaler.y, scaler.z);
      // Scale the plane to fill the view
      // plane.scale.set(1.5, 1.5, 1.5);
      plane.renderOrder = -1;

      // Initialize Three.js scene
      const container = document.getElementById("container");
      const threeScene = createScene(container);
      scene = threeScene.scene;
      camera = threeScene.camera;
      renderer = threeScene.renderer;

      renderer.getContext().enableVertexAttribArray(1);

      // Add the plane to the scene
      scene.add(plane);

      const attachFaustNode = async () => {
        await faustNode.then((faustNode) => {
          console.log("faustNode", faustNode.setParamValue);
          window.faustNode = faustNode;
          faustNode.setParamValue("/hand_synth/gate", 1.0);
          console.log("faustNode attached");
        });
      };

      // Add after renderer initialization

      // Replace or modify the createScene function
      function createScene(container) {
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(
          75,
          window.innerWidth / window.innerHeight,
          0.1,
          10000
        );
        camera.position.z = 5;

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        container.appendChild(renderer.domElement);

        // Add post-processing setup
        composer = new THREE.EffectComposer(renderer);
        const renderPass = new THREE.RenderPass(scene, camera);
        composer.addPass(renderPass);

        if (SHADERS_ENABLED) {
          const distortionPass = new THREE.ShaderPass(LensDistortionShader);
          distortionPass.renderToScreen = true;
          composer.addPass(distortionPass);
        }

        return { scene, camera, renderer };
      }

      // Modify the animate function
      function animate() {
        requestAnimationFrame(animate);

        if (SHADERS_ENABLED) {
          if (
            window.lastFaceLandmarks !== undefined &&
            window.lastFaceLandmarks.length > 0
          ) {
            const time = Date.now() * 0.001;
            let noseZ = window.lastFaceLandmarks[0].z;
            noseZ =
              noseZ.remap(-0.08561716973781586, 0.011626691557466984, 0, 1) *
              30;

            if (noseZ < 0) {
              noseZ = Math.abs(noseZ) * -300;
            }

            const distortionValue = -1.0;

            // Update shader uniforms
            composer.passes[1].uniforms.distortion.value = distortionValue;
            composer.passes[1].uniforms.rightEyePoints.value =
              window.lastRightEyeLandmarks;
            composer.passes[1].uniforms.leftEyePoints.value =
              window.lastLeftEyeLandmarks;

            // Store current frame in previous frame texture
            renderer.setRenderTarget(prevFrameTarget);
            composer.render();

            // Set previous frame texture in shader
            composer.passes[1].uniforms.tPrevious.value =
              prevFrameTarget.texture;

            // Render final output
            renderer.setRenderTarget(null);
            composer.render();
          } else {
            const time = Date.now() * 0.001;
            const distortionValue = 0.3 + Math.sin(time) * 0.2;
            composer.passes[1].uniforms.distortion.value = distortionValue;
            composer.render();
          }
        } else {
          renderer.render(scene, camera);
        }
      }

      animate();

      const debugDiv = document.createElement("div");
      debugDiv.id = "debug-text";
      document.body.appendChild(debugDiv);

      const showDebugText = (results) => {
        let debugText = "";
        if (results.multiHandLandmarks.length === 0) {
          debugText = "No hands detected";
          updateFaustParamsNoLandmarks(window.faustNode);
        } else {
          debugText = results.multiHandLandmarks
            .map((landmarks, index) => formatLandmarks(landmarks, index))
            .join("\n\n");
        }
        debugDiv.textContent = debugText;
      };

      function formatLandmarks(landmarks, handIndex) {
        const landmarkNames = [
          "wrist",
          "thumb_cmc",
          "thumb_mcp",
          "thumb_ip",
          "thumb_tip",
          "index_mcp",
          "index_pip",
          "index_dip",
          "index_tip",
          "middle_mcp",
          "middle_pip",
          "middle_dip",
          "middle_tip",
          "ring_mcp",
          "ring_pip",
          "ring_dip",
          "ring_tip",
          "pinky_mcp",
          "pinky_pip",
          "pinky_dip",
          "pinky_tip",
        ];

        let display = landmarks
          .map((landmark, i) => {
            return (
              `Hand ${handIndex + 1} - ${landmarkNames[i]}:` +
              `  x: ${landmark.x.toFixed(3)}` +
              `  y: ${landmark.y.toFixed(3)}` +
              `  z: ${landmark.z.toFixed(8)}`
            );
          })
          .join("\n");

        return display;
      }

      function onResults(results) {
        // Modify the scene clearing to preserve the video plane
        const objectsToRemove = scene.children.filter(
          (child) => child !== plane
        );

        objectsToRemove.forEach((object) => scene.remove(object));

        if (results.multiHandLandmarks) {
          updateFaustParamsForLandmarks(window.faustNode);
          showDebugText(results);
          let i = 0;
          for (const landmarks of results.multiHandLandmarks) {
            // Transform landmarks to match plane coordinates
            const transformedLandmarks = landmarks.map((landmark) => ({
              x: (landmark.x - 0.5) * pointScaler.x + 0.5,
              y: (landmark.y - 0.5) * pointScaler.y + 0.5,
              z: landmark.z * pointScaler.z || 0,
            }));

            window.lastHandLandmarks = transformedLandmarks;

            drawConnectors(scene, transformedLandmarks, HAND_CONNECTIONS, {
              color: 0x00ff00,
              lineWidth: 2,
            });

            drawLandmarks(scene, transformedLandmarks, {
              color: 0xffffff,
              radius: 4,
              // scaler: pointScaler * poin,
            });

            updateFaustParams(window.faustNode, landmarks); // Keep original landmarks for Faust params
            ++i;
          }
        }
      }

      const hands = new Hands({
        locateFile: (file) => `./modules/hands_files/${file}`,
      });

      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });

      hands.onResults(onResults);

      // Add this import after the existing mediapipe import

      // console.log("AHHHHHHHHHHHHHHHHH", FilesetResolver);

      // Add these declarations near the top of your module script
      // import { FaceMesh } from "@mediapipe/face_mesh";
      // import { FilesetResolver, FaceDetector } from "@mediapipe/tasks-vision";

      // Remove the incorrect face detector initialization and replace with:
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );

      const faceDetector = await FaceDetector.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`,
          delegate: "GPU",
          model: "short",
        },
        runningMode: "VIDEO",
      });

      const faceMesh = new FaceMesh({
        locateFile: (file) => {
          return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
        },
      });

      // Add face mesh results handler
      faceMesh.onResults((results) => {
        if (results.multiFaceLandmarks) {
          for (const landmarks of results.multiFaceLandmarks) {
            // You can add face mesh visualization here similar to hand landmarks

            const transformedLandmarks = landmarks.map((landmark) => ({
              x: (landmark.x - 0.5) * pointScaler.x + 0.5,
              y: (landmark.y - 0.5) * pointScaler.y + 0.5,
              z: landmark.z * pointScaler.z || 0,
            }));

            window.lastFaceLandmarks = transformedLandmarks;
            let rightEyePoints = [];

            for (let i = 0; i < EYE_POINTS.RIGHT_EYE.length; i++) {
              let x = landmarks[EYE_POINTS.RIGHT_EYE[i]].x,
                y = landmarks[EYE_POINTS.RIGHT_EYE[i]].y;
              rightEyePoints[i] = new THREE.Vector3(
                (x - 0.5) * 0.8 + 0.5,
                (1 - y - 0.5) * 0.7 + 0.5,
                landmarks[EYE_POINTS.RIGHT_EYE[i]].z * pointScaler.z || 0
              );
            }

            for (let i = 0; i < EYE_POINTS.LEFT_EYE.length; i++) {
              let x = landmarks[EYE_POINTS.LEFT_EYE[i]].x,
                y = landmarks[EYE_POINTS.LEFT_EYE[i]].y;
              leftEyePoints[i] = new THREE.Vector3(
                (x - 0.5) * 0.8 + 0.5,
                (1 - y - 0.5) * 0.7 + 0.5,
                landmarks[EYE_POINTS.LEFT_EYE[i]].z * pointScaler.z || 0
              );
            }

            const referancePoints = [
              new THREE.Vector3(0.25, 0.25, 0),
              new THREE.Vector3(0.25, 0.5, 0),
              new THREE.Vector3(0.25, 0.75, 0),

              new THREE.Vector3(0.5, 0.25, 0),
              new THREE.Vector3(0.5, 0.5, 0),
              new THREE.Vector3(0.5, 0.75, 0),

              new THREE.Vector3(0.75, 0.25, 0),
              new THREE.Vector3(0.75, 0.5, 0),
              new THREE.Vector3(0.75, 0.75, 0),
            ];

            for (let i = 0; i < referancePoints.length; i++) {
              referancePoints[i].x =
                (referancePoints[i].x - 0.5) * aspectRatio * 3.8 + 0.5;
              referancePoints[i].y = (referancePoints[i].y - 0.5) * 3.8 + 0.5;
              referancePoints[i].z = 0;
            }

            drawLandmarks(scene, referancePoints, {
              color: 0x00ff00,
              radius: 4,
            });

            drawLandmarks(scene, [leftEyePoints, rightEyePoints], {
              color: 0x00ff00,
              radius: 4,
            });

            window.lastRightEyeLandmarks = rightEyePoints;
            window.lastLeftEyeLandmarks = leftEyePoints;
            // console.log(rightEyePoints[0].x);
            // console.log(window.lastLeftEyeLandmarks);

            // findZRange(transformedLandmarks[FACE_LANDMARKS.RIGHT_EYE].z);

            // Draw a single point at 0.5, 0.5
            const centerPoint = new THREE.Vector3(0.5, 0.5, 0);
            const leftPoint = new THREE.Vector3(0.0, 0.5, 0);
            const rightPoint = new THREE.Vector3(1.0, 0.5, 0);

            drawLandmarks(scene, transformedLandmarks, {
              color: 0x0000ff,
              lineWidth: 1,
              radius: 1,
            });
          }
        }
      });

      // Modify your camera setup to process both hands and face
      const canvasCamera = new Camera(videoElement, {
        onFrame: async () => {
          await hands.send({ image: videoElement });
          await faceMesh.send({ image: videoElement });
        },
        width: window.innerWidth,
        height: window.innerHeight,
        facingMode: "environment",
      });
      // videoElement.style.visibility = "hidden";
      canvasCamera.start();
      console.log(canvasCamera);

      // aspectRatio = canvasCamera.h.width / canvasCamera.h.height;

      await attachFaustNode();

      // Add after composer initialization
      const prevFrameTarget = new THREE.WebGLRenderTarget(
        window.innerWidth * window.devicePixelRatio,
        window.innerHeight * window.devicePixelRatio
      );
    </script>
  </head>

  <body>
    <div id="container"></div>
  </body>
</html>
